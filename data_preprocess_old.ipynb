{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQWCJQYYBGpOLeUTlosi2o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayushi15092002/mental-health-workload/blob/main/data_preprocess_old.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqLI63kNFOZS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a531c0a-334c-4bc5-e367-8a0e9329de9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mne"
      ],
      "metadata": {
        "id": "sUVZbpgRFZaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mne\n",
        "import os\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "f-Sa7VX8FcAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subjectData = \"/content/drive/My Drive/drdo/subjects\"\n",
        "cleanData = \"/content/drive/My Drive/drdo/cleanData_new\"\n",
        "fname= \"/content/drive/My Drive/drdo/channel_loc.csv\"\n",
        "read_dataset(subjectData)"
      ],
      "metadata": {
        "id": "fv_ZliIWFcza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleanData = \"/content/drive/My Drive/drdo/cleanData_new\"\n",
        "fname= \"/content/drive/My Drive/drdo/channel_loc.csv\"\n",
        "path_file_vhdr = '/content/drive/My Drive/drdo/subjects/VP001/nback1.vhdr'\n",
        "path_file_vmrk = '/content/drive/My Drive/drdo/subjects/VP001/nback1.vmrk'\n",
        "preprocess(path_file_vhdr, path_file_vmrk, \"VP001\", \"nback1\")"
      ],
      "metadata": {
        "id": "Cpir9TciDzkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_dataset(subjectPath):\n",
        "    \n",
        "    try:\n",
        "        root, dirs, files = next(os.walk(subjectPath))\n",
        "        \n",
        "        for folder_name in dirs:\n",
        "          path_file_vhdr = subjectPath + '/' + folder_name + '/nback1.vhdr'\n",
        "          path_file_vmrk = subjectPath + '/' + folder_name + '/nback1.vmrk'\n",
        "          preprocess(path_file_vhdr, path_file_vmrk, folder_name, \"nback1\")\n",
        "\n",
        "          path_file_vhdr = subjectPath + '/' + folder_name + '/nback2.vhdr'\n",
        "          path_file_vmrk = subjectPath + '/' + folder_name + '/nback2.vmrk'\n",
        "          preprocess(path_file_vhdr, path_file_vmrk, folder_name, \"nback2\")\n",
        "\n",
        "          path_file_vhdr = subjectPath + '/' + folder_name + '/nback3.vhdr'\n",
        "          path_file_vmrk = subjectPath + '/' + folder_name + '/nback3.vmrk'\n",
        "          preprocess(path_file_vhdr, path_file_vmrk,folder_name,\"nback3\")\n",
        "\n",
        "          # path_file_vhdr = subjectPath + '/' + folder_name + '/gonogo1.vhdr'\n",
        "          # path_file_vmrk = subjectPath + '/' + folder_name + '/gonogo1.vmrk'\n",
        "          # preprocess(path_file_vhdr, path_file_vmrk, folder_name, \"gonogo1\",2)\n",
        "\n",
        "          # path_file_vhdr = subjectPath + '/' + folder_name + '/gonogo2.vhdr'\n",
        "          # path_file_vmrk = subjectPath + '/' + folder_name + '/gonogo2.vmrk'\n",
        "          # preprocess(path_file_vhdr, path_file_vmrk, folder_name, \"gonogo2\",2)\n",
        "\n",
        "          # path_file_vhdr = subjectPath + '/' + folder_name + '/gonogo3.vhdr'\n",
        "          # path_file_vmrk = subjectPath + '/' + folder_name + '/gonogo3.vmrk'\n",
        "          # preprocess(path_file_vhdr, path_file_vmrk,folder_name,\"gonogo3\",2)\n",
        "\n",
        "          # path_file_vhdr = subjectPath + '/' + folder_name + '/word1.vhdr'\n",
        "          # path_file_vmrk = subjectPath + '/' + folder_name + '/word1.vmrk'\n",
        "          # preprocess(path_file_vhdr, path_file_vmrk, folder_name, \"word1\",3)\n",
        "\n",
        "          # path_file_vhdr = subjectPath + '/' + folder_name + '/word2.vhdr'\n",
        "          # path_file_vmrk = subjectPath + '/' + folder_name + '/word2.vmrk'\n",
        "          # preprocess(path_file_vhdr, path_file_vmrk, folder_name, \"word2\",3)\n",
        "\n",
        "          # path_file_vhdr = subjectPath + '/' + folder_name + '/word3.vhdr'\n",
        "          # path_file_vmrk = subjectPath + '/' + folder_name + '/word3.vmrk'\n",
        "          # preprocess(path_file_vhdr, path_file_vmrk,folder_name,\"word3\",3)\n",
        "\n",
        "            \n",
        "    except StopIteration:\n",
        "        pass\n",
        "        print(\"Error ocurred:\")\n",
        "        print(\"Directory with dataset does not found!\")\n",
        "        print(\"Program will be terminated\")\n",
        "        exit(1)"
      ],
      "metadata": {
        "id": "fBq3bfXVGHPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(path_file_vhdr, path_file_vmrk, subject_name , session_name):\n",
        "\n",
        "\n",
        "  TUB_montage = mne.channels.read_custom_montage(fname)\n",
        "\n",
        "  # matplotlib.use('Qt5Agg')\n",
        "  # %matplotlib widget\n",
        "  # %matplotlib qt\n",
        "  # %gui qt\n",
        "  # mne.viz.set_3d_backend(\"notebook\")\n",
        "\n",
        "  raw = mne.io.read_raw_brainvision(path_file_vhdr, eog=('HEOG', 'VEOG'), preload=True)\n",
        "\n",
        "  raw.set_montage(TUB_montage)\n",
        "  # print(\"raw.info >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\", raw.info)\n",
        "  raw.plot(start=0, duration=6)\n",
        "\n",
        "  mrk = mne.read_annotations(path_file_vmrk, sfreq='auto', uint16_codec=None)\n",
        "\n",
        "  raw_downsampled = raw.copy().resample(sfreq=200)\n",
        "\n",
        "  raw_filtered = raw_downsampled.copy().filter(l_freq=1 , h_freq= 40)\n",
        "  raw_filtered.plot()\n",
        "\n",
        "  raw_notch_filtered = raw_filtered.notch_filter(50, filter_length='auto', phase='zero')\n",
        "  raw_notch_filtered.plot()  \n",
        "\n",
        "  raw_re_referenced = mne.set_eeg_reference(raw_notch_filtered,ref_channels='average',copy=True, projection=False)\n",
        "  finData, times = raw_re_referenced[:]\n",
        "  finData.plot()\n",
        "\n",
        "  fig, ax = plt.subplots(2)\n",
        "  raw.plot_psd(ax=ax[0], show = False, fmax = 60)\n",
        "  finData.plot_psd(ax=ax[1], show = False, fmax=60)\n",
        "  ax[0].set_title(\"PSD before filtering\")\n",
        "  ax[1].set_title(\"PSD after filtering\")\n",
        "  ax[1].set_xlabel('Frequency(Hz)')\n",
        "  fig.set_tight_layout(True)\n",
        "  plt.show()\n",
        "\n",
        "  n_components = 10 #number of components you want to fit # can be either integer which typically implies number of channels - 1 (if applied average reference)\n",
        "                  #if floating point number (0-1) fraction of total explained variance\n",
        "  method = 'fastica'\n",
        "  max_iter = 100\n",
        "  fit_params = dict(fastica_it = 5)\n",
        "  random_state = 42\n",
        "  ica = mne.preprocessing.ICA(n_components = n_components,\n",
        "                              method = method,\n",
        "                              max_iter=max_iter,\n",
        "                              random_state= random_state\n",
        "                              )\n",
        "  ica.fit(finData)\n",
        "\n",
        "  finData.load_data()\n",
        "  ica.plot_sources(finData, show_scrollbars=False)\n",
        "  ica.plot_components(sphere=1)\n",
        "\n",
        "  #Manual Eye Artifact Removal\n",
        "  # ica.exclude = [0, 3]  \n",
        "  # reconst_raw = finData.copy()\n",
        "  # ica.apply(reconst_raw)\n",
        "  # finData.plot(title = \"finData\")\n",
        "  # reconst_raw.plot(title = \"Manual\")\n",
        "\n",
        "  #Automatic (Threshold Based) Eye Artifact Removal\n",
        "  ica.exclude = []\n",
        "  reconst_raw = finData.copy()\n",
        "  # find which ICs match the EOG pattern\n",
        "  eog_indices, eog_scores = ica.find_bads_eog(finData, threshold = 2.5)\n",
        "  ica.exclude = eog_indices\n",
        "  ica.apply(reconst_raw)\n",
        "  #print(eog_indices)\n",
        "  reconst_raw.plot(title=\"Automatic\")\n",
        "\n",
        "  reconst_raw.plot()\n",
        "\n",
        "  # if dataset == 1:\n",
        "  events_ids = {\n",
        "    'Stimulus/S 16': 16,\n",
        "    'Stimulus/S 48': 48,\n",
        "    'Stimulus/S 64': 64,\n",
        "    'Stimulus/S 80': 80,\n",
        "    'Stimulus/S 96': 96,\n",
        "    'Stimulus/S112': 112,\n",
        "    'Stimulus/S128': 128,\n",
        "    'Stimulus/S144': 144}\n",
        "\n",
        "  # elif dataset == 2:\n",
        "  #   events_ids = {\n",
        "  #     'Stimulus/S 16': 16,\n",
        "  #     'Stimulus/S 32': 32,\n",
        "  #     'Stimulus/S 48': 48}\n",
        "\n",
        "  # elif dataset == 3:\n",
        "  #   events_ids = {\n",
        "  #     'Stimulus/S 16': 16,\n",
        "  #     'Stimulus/S 32': 32}\n",
        "\n",
        "  \n",
        "  # events_ids\n",
        "\n",
        "  event,event_ids = mne.events_from_annotations(reconst_raw)\n",
        "  print(\"events >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\", event)\n",
        "  print(\"event_ids >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\",event_ids)\n",
        "  \n",
        "  mne.viz.plot_events(event,event_id = events_ids, sfreq=raw.info['sfreq'])\n",
        "\n",
        "  # tmin=-5 # when does the epoch start relative to the event onset # 300ms before the start of the event\n",
        "  # tmax=60  # when does the event end after the even onset # 500 ms from the start of the event\n",
        "  # #Is a tuple containing the start of the baseline and end of the baseline\n",
        "  # baseline= (-5, -2) #None mean begnining of the event and 0 is the start of the event \n",
        "\n",
        "  tmin=-0.3 # when does the epoch start relative to the event onset # 300ms before the start of the event\n",
        "  tmax=1.7  # when does the event end after the even onset # 500 ms from the start of the event\n",
        "\n",
        "  # #Is a tuple containing the start of the baseline and end of the baseline\n",
        "  baseline= (None, 0) #None mean begnining of the event and 0 is the start of the event \n",
        "  \n",
        "  epochs = mne.Epochs(reconst_raw, \n",
        "                      events=event,\n",
        "                      event_id=event_ids,\n",
        "                      tmin=tmin,tmax=tmax, \n",
        "                      baseline=baseline,\n",
        "                      preload=True,event_repeated = 'drop')\n",
        "  \n",
        "  epochs.plot_drop_log()\n",
        "\n",
        "  back_0_list = [mne.EpochsArray(epochs['Stimulus/S 16'], epochs.info), mne.EpochsArray(epochs['Stimulus/S112'], epochs.info)]\n",
        "  epochs_0_back = mne.concatenate_epochs(back_0_list)\n",
        "  back_1_list = [mne.EpochsArray(epochs['Stimulus/S 48'], epochs.info), mne.EpochsArray(epochs['Stimulus/S 64'], epochs.info),  mne.EpochsArray(epochs['Stimulus/S128'], epochs.info)]\n",
        "  epochs_1_back = mne.concatenate_epochs(back_1_list)\n",
        "  back_2_list = [mne.EpochsArray(epochs['Stimulus/S 80'], epochs.info), mne.EpochsArray(epochs['Stimulus/S 96'], epochs.info),  mne.EpochsArray(epochs['Stimulus/S144'], epochs.info)]\n",
        "  epochs_2_back = mne.concatenate_epochs(back_2_list)\n",
        "\n",
        "  epochs.plot(events=event, event_id = event_ids)\n",
        "\n",
        "  export_dir = cleanData + \"/\"\n",
        "\n",
        "  if session_name == \"nback1\":\n",
        "    session_id = \"1\"\n",
        "  elif session_name == \"nback2\":\n",
        "    session_id = \"2\"\n",
        "  else:\n",
        "    session_id = \"3\"\n",
        "  try:\n",
        "    os.makedirs(export_dir)\n",
        "  except FileExistsError:\n",
        "    pass\n",
        "  try:\n",
        "    back_0_filepath = export_dir + \"/0_back\" + \"/\" +subject_name + \"_\"+session_id +\".fif\"\n",
        "    back_1_filepath = export_dir + \"/2_back\" + \"/\" +subject_name + \"_\"+session_id +\".fif\"\n",
        "    back_2_filepath = export_dir + \"/3_back\" + \"/\" +subject_name + \"_\"+session_id +\".fif\"\n",
        "    mne.Epochs.save(epochs_0_back,fname=back_0_filepath,overwrite=True)\n",
        "    mne.Epochs.save(epochs_1_back,fname=back_1_filepath,overwrite=True)\n",
        "    mne.Epochs.save(epochs_2_back,fname=back_2_filepath,overwrite=True)\n",
        "  except FileExistsError:\n",
        "    pass"
      ],
      "metadata": {
        "id": "etSUR03eGOfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qo1MRKgHcOMa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}