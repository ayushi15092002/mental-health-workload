{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "pK8VC1XyZTXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFj4H2P6nBMT"
      },
      "outputs": [],
      "source": [
        "pip install mne --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install signal-processing"
      ],
      "metadata": {
        "id": "A3xLOG88iqTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install autoreject"
      ],
      "metadata": {
        "id": "CgukLijxjc4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHbAQmd9nBMS"
      },
      "outputs": [],
      "source": [
        "!pip install sklearn.cross_validation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install matplotlib==3.1.1\n"
      ],
      "metadata": {
        "id": "RAsxX6kI1WW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xm293g4LnBMU"
      },
      "outputs": [],
      "source": [
        "import mne,os\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from time import time\n",
        "from sklearn import metrics\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "import random\n",
        "from signal_processing import *\n",
        "from cmath import nan\n",
        "from autoreject import get_rejection_threshold\n",
        "from autoreject import AutoReject"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Start**"
      ],
      "metadata": {
        "id": "8S-jJZXxZy08"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Set **A**"
      ],
      "metadata": {
        "id": "AYuRYd5rQe3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subjectData = \"/content/drive/My Drive/drdo/subjects\"\n",
        "cleanData = \"/content/drive/My Drive/drdo/cleanData\"\n",
        "fname= \"/content/drive/My Drive/drdo/channel_loc.csv\"\n",
        "TUB_montage = mne.channels.read_custom_montage(fname)\n",
        "# path_file_vhdr1 = '/content/drive/My Drive/drdo/subjects/VP003/nback2.vhdr'\n",
        "# path_file_vmrk1 = '/content/drive/My Drive/drdo/subjects/VP003/nback2.vmrk'\n",
        "# preprocess_datasetA(path_file_vhdr1, path_file_vmrk1, \"VP001\", \"nback1\")\n",
        "\n",
        "read_datasetA(subjectData)"
      ],
      "metadata": {
        "id": "_abGggrNQ5I_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fname= \"/content/drive/My Drive/drdo/channel_loc.csv\"\n",
        "# Read a montage from a file.\n",
        "TUB_montage = mne.channels.read_custom_montage(fname)\n",
        "\n",
        "def read_datasetA(subjectPath):\n",
        "    \n",
        "    try:\n",
        "        root, dirs, files = next(os.walk(subjectPath))\n",
        "        \n",
        "        for folder_name in dirs:\n",
        "          path_file_vhdr1 = subjectPath + '/' + folder_name + '/nback1.vhdr'\n",
        "          path_file_vmrk1 = subjectPath + '/' + folder_name + '/nback1.vmrk'\n",
        "          preprocess_datasetA(path_file_vhdr1, path_file_vmrk1, folder_name, \"nback1\")\n",
        "\n",
        "          path_file_vhdr2 = subjectPath + '/' + folder_name + '/nback2.vhdr'\n",
        "          path_file_vmrk2 = subjectPath + '/' + folder_name + '/nback2.vmrk'\n",
        "          preprocess_datasetA(path_file_vhdr2, path_file_vmrk2, folder_name, \"nback2\")\n",
        "\n",
        "          path_file_vhdr3 = subjectPath + '/' + folder_name + '/nback3.vhdr'\n",
        "          path_file_vmrk3 = subjectPath + '/' + folder_name + '/nback3.vmrk'\n",
        "          preprocess_datasetA(path_file_vhdr3, path_file_vmrk3,folder_name,\"nback3\")\n",
        "            \n",
        "    except StopIteration:\n",
        "        pass\n",
        "        print(\"Error ocurred:\")\n",
        "        print(\"Directory with dataset does not found!\")\n",
        "        print(\"Program will be terminated\")\n",
        "        exit(1)\n"
      ],
      "metadata": {
        "id": "L2ubrcHwDptT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_datasetA(path_file_vhdr, path_file_vmrk, subject_name , session_name):\n",
        "  raw = mne.io.read_raw_brainvision(path_file_vhdr, eog=('HEOG', 'VEOG'), preload=True)  # read raw data of the subject\n",
        "  raw.set_montage(TUB_montage)\n",
        "  if (raw.info['nchan'] == 4):\n",
        "    raw = raw.drop_channels(['EOG'])  # EOG channel is deleted\n",
        "  # read annotations from a file.\n",
        "  raw.info\n",
        "  raw.plot(start=0, duration=6)\n",
        "  mrk = mne.read_annotations(path_file_vmrk, sfreq='auto', uint16_codec=None)\n",
        "  raw_downsampled = raw.copy().resample(sfreq=256)\n",
        "  raw_filtered = raw_downsampled.copy().filter(l_freq=0.1 , h_freq= 45)\n",
        "  raw_notch_filtered = raw_filtered.notch_filter(50, filter_length='auto', phase='zero')\n",
        "\n",
        "  eog_projs, _ = mne.preprocessing.compute_proj_eog(raw_notch_filtered,verbose=False,n_grad=0,n_mag=0,n_eeg=1,reject=None,no_proj=True,ch_name=['HEOG', 'VEOG'])\n",
        "  raw_notch_filtered.add_proj(eog_projs,remove_existing=True)\n",
        "  raw_notch_filtered.apply_proj()\n",
        "  raw_notch_filtered.drop_channels(['HEOG', 'VEOG']) # later remove this from filter funct\n",
        "  # raw_notch_filtered.plot()  \n",
        "  raw_re_referenced = mne.set_eeg_reference(raw_notch_filtered, ref_channels='average', copy=True, projection=False) \n",
        "  finData, times = raw_re_referenced[:]\n",
        "  finData.plot()\n",
        "  print(\"times\")\n",
        "  print(times)\n",
        "  # fig, ax = plt.subplots(2)\n",
        "  # # raw.plot_psd(ax=ax[0], show = False, fmax = 60)\n",
        "  # finData.plot_psd(ax=ax[1], show = False, fmax=60)\n",
        "  # ax[0].set_title(\"PSD before filtering\")\n",
        "  # ax[1].set_title(\"PSD after filtering\")\n",
        "  # ax[1].set_xlabel('Frequency(Hz)')\n",
        "  # fig.set_tight_layout(True)\n",
        "  # plt.show()\n",
        "  n_components = 27 #number of components you want to fit # can be either integer which typically implies number of channels - 1 (if applied average reference)\n",
        "  #     #if floating point number (0-1) fraction of total explained variance\n",
        "  method = 'fastica'\n",
        "  max_iter = 100\n",
        "  fit_params = dict(fastica_it = 5)\n",
        "  random_state = 42\n",
        "  ica = mne.preprocessing.ICA(n_components = n_components,\n",
        "                              method = method,\n",
        "                              max_iter=max_iter,\n",
        "                              random_state= random_state)\n",
        "  ica.fit(finData)\n",
        "  finData.load_data()\n",
        "  # ica.plot_sources(finData, show_scrollbars=False)\n",
        "  # ica.plot_components(sphere=1)\n",
        "  ica.exclude = []\n",
        "  reconst_raw = finData.copy()\n",
        "  # # find which ICs match the EOG pattern\n",
        "  # eog_indices, eog_scores = ica.find_bads_eog(finData, threshold = 2.5)\n",
        "  # ica.exclude = eog_indices\n",
        "  ica.apply(reconst_raw)\n",
        "  # #print(eog_indices)\n",
        "  print(\"after >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
        "  reconst_raw.plot(title=\"Automatic\")\n",
        "\n",
        "  events_loaded = mne.events_from_annotations(raw)\n",
        "\n",
        "  tmin=-0.3 # when does the epoch start relative to the event onset # 300ms before the start of the event\n",
        "  tmax=1.7  # when does the event end after the even onset # 500 ms from the start of the event\n",
        "\n",
        "  # #Is a tuple containing the start of the baseline and end of the baseline\n",
        "  baseline= (None, 0) #None mean begnining of the event and 0 is the start of the event \n",
        "  event_ids = {\n",
        "      'Stimulus/S 16': 16,\n",
        "      'Stimulus/S 48': 48,\n",
        "      'Stimulus/S 64': 64,\n",
        "      'Stimulus/S 80': 80,\n",
        "      'Stimulus/S 96': 96,\n",
        "      'Stimulus/S 112': 112,\n",
        "      'Stimulus/S 128': 128,\n",
        "      'Stimulus/S 144': 144,\n",
        "  }\n",
        "\n",
        "  events,event_ids = mne.events_from_annotations(reconst_raw, event_ids)\n",
        "\n",
        "  epochs = mne.Epochs(reconst_raw, \n",
        "                      events=events,\n",
        "                      event_id=event_ids,\n",
        "                      tmin=tmin,tmax=tmax, \n",
        "                      baseline=baseline,\n",
        "                      preload=True,event_repeated = 'drop')\n",
        "  # epochs = mne.Epochs(reconst_raw,buttontarget_events,event_id=event_dict,tmin=tminmax[0],tmax=tminmax[1],\n",
        "  #                           baseline=baseline,picks=picks,preload=True)\n",
        "        \n",
        "  # Plot the epochs' GFP plot before artefact rejection\n",
        "  name = subject_name + \"_\" + session_name\n",
        "  epochs.plot_image(title=\"GFP without AR ({})\".format(name))\n",
        "\n",
        "  # Use AutoReject to repair and remove epochs which are artefactual\n",
        "  reject_criteria = get_rejection_threshold(epochs)\n",
        "  print('Dropping epochs with rejection threshold:',reject_criteria)\n",
        "  epochs.drop_bad(reject=reject_criteria)\n",
        "\n",
        "  ar = AutoReject(thresh_method='random_search',random_state=42)\n",
        "  ar.fit(epochs)\n",
        "  epochs_ar, reject_log = ar.transform(epochs, return_log=True)\n",
        "\n",
        "  print(\"log >>>>>>>>>>>>>>>\")\n",
        "  reject_log.plot('horizontal')\n",
        "  print(\"epoches >>>>>>>>>>>>>>>>\")\n",
        "   # Plot the epochs' GFP after artefact rejection\n",
        "  # epochs_ar.average().plot()\n",
        "  epochs_ar.plot_image(title=\"GFP with AR ({})\".format(name))\n",
        "   # Display the final epochs object meta-data\n",
        "  display(epochs_ar)\n",
        "\n",
        "\n",
        "  export_dir = cleanData + \"/\" + subject_name\n",
        "  try:\n",
        "    os.makedirs(export_dir)\n",
        "  except FileExistsError:\n",
        "    pass\n",
        "  try:\n",
        "    filepath = export_dir + \"/\"+session_name +\".fif\"\n",
        "    mne.Epochs.save(epochs,fname=filepath,overwrite=True)\n",
        "  except FileExistsError:\n",
        "    pass\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JHA476Pp9RFb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "cd91674b2cd8459bb54b75adbb7ab2158a31a0c75b92ca363f579e52d7bec96e"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}